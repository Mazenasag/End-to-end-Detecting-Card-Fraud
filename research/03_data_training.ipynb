{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1d1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d8f76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Mlop\\\\End to end\\\\End-to-end-Detecting-Card-Fraud\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98efe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b97bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a503e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTrainingConfig:\n",
    "    processed_train_path: Path\n",
    "    processed_test_path: Path\n",
    "    model_dir: Path\n",
    "    model_pkl_file: Path\n",
    "    max_depth: List\n",
    "    min_samples_split: List\n",
    "    min_samples_leaf: List\n",
    "    max_features: List\n",
    "    n_estimators: List\n",
    "    learning_rate: List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88723f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CardFraud.constant import*\n",
    "from CardFraud.utils.common import read_yaml , create_directories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f4669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "    def get_data_training_config(self) -> DataTrainingConfig:\n",
    "        data_training_config = DataTrainingConfig(\n",
    "            processed_train_path=self.config.data_training.processed_train_path,\n",
    "            processed_test_path=self.config.data_training.processed_test_path,\n",
    "            model_dir=self.config.data_training.model_dir,\n",
    "            model_pkl_file=self.config.data_training.model_pkl_file,\n",
    "            max_depth=self.params.training_params.max_depth,\n",
    "            min_samples_split=self.params.training_params.min_samples_split,\n",
    "            min_samples_leaf=self.params.training_params.min_samples_leaf,\n",
    "            max_features=self.params.training_params.max_features,\n",
    "            n_estimators=self.params.training_params.n_estimators,\n",
    "            learning_rate=self.params.training_params.learning_rate\n",
    "        )\n",
    "        return data_training_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0711139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTrainingConfig(processed_train_path='data/processed_data/preprocessed_train.csv', processed_test_path='data/processed_data/preprocessed_test.csv', model_dir='models/', model_pkl_file='models/model.pkl', max_depth=BoxList([5]), min_samples_split=BoxList([10]), min_samples_leaf=BoxList([10]), max_features=BoxList(['sqrt']), n_estimators=BoxList([30]), learning_rate=BoxList([0.1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=ConfigurationManager()\n",
    "d.get_data_training_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f51baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a73e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: DataTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self, trainpath: Path, testpath: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        try:\n",
    "            train = pd.read_csv(trainpath)\n",
    "            test = pd.read_csv(testpath)\n",
    "            logging.info(f\"Data loaded successfully from {trainpath} and {testpath}\")\n",
    "            return train, test\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def split_data(self, train_data: pd.DataFrame, test_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "        try:\n",
    "            X_train = train_data.drop(\"Class\", axis=1)\n",
    "            y_train = train_data[\"Class\"]\n",
    "            X_test = test_data.drop(\"Class\", axis=1)\n",
    "            y_test = test_data[\"Class\"]\n",
    "            logging.info(\"Data split successfully\")\n",
    "            return X_train, y_train, X_test, y_test\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def get_models(self) -> Dict[str, object]:\n",
    "        \"\"\"Define the models to be trained.\"\"\"\n",
    "        models = {\n",
    "            \"LogisticRegression\": LogisticRegression(),\n",
    "            \"RandomForest\": RandomForestClassifier(),\n",
    "            \"DecisionTree\": DecisionTreeClassifier(),\n",
    "            \"XGBoost\": xgb.XGBClassifier()\n",
    "        }\n",
    "        return models\n",
    "\n",
    "    def get_params(self) -> Dict[str, dict]:\n",
    "        \"\"\"Fetch parameters from the configuration.\"\"\"\n",
    "        param_grid = {\n",
    "            \"LogisticRegression\": {\n",
    "                \"C\": [0.1, 1],\n",
    "                \"solver\": [\"liblinear\"],\n",
    "                \"max_iter\": [100, 200]\n",
    "            },\n",
    "            \"RandomForest\": {\n",
    "                \"n_estimators\": self.config.n_estimators,\n",
    "                \"max_depth\": self.config.max_depth,\n",
    "                \"min_samples_split\": self.config.min_samples_split,\n",
    "                \"min_samples_leaf\": self.config.min_samples_leaf,\n",
    "                \"max_features\": self.config.max_features\n",
    "            },\n",
    "            \"DecisionTree\": {\n",
    "                \"max_depth\": self.config.max_depth,\n",
    "                \"min_samples_split\": self.config.min_samples_split,\n",
    "                \"min_samples_leaf\": self.config.min_samples_leaf,\n",
    "                \"max_features\": self.config.max_features\n",
    "            },\n",
    "            \"XGBoost\": {\n",
    "                \"n_estimators\": self.config.n_estimators,\n",
    "                \"learning_rate\": self.config.learning_rate,\n",
    "                \"max_depth\": self.config.max_depth\n",
    "            }\n",
    "        }\n",
    "        return param_grid\n",
    "\n",
    "\n",
    "\n",
    "    # def training(self, X_train: pd.DataFrame, y_train: pd.Series) -> Dict[str, object]:\n",
    "    #     \"\"\"Train the models using randomized search with parameters defined in the config.\"\"\"\n",
    "    #     models = self.get_models()\n",
    "    #     param_grid = self.get_params()\n",
    "    #     trained_models = {}\n",
    "\n",
    "    #     # for model_name, model in models.items():\n",
    "    #     #     try:\n",
    "        #         logging.info(f\"Training {model_name} with RandomizedSearchCV...\")\n",
    "\n",
    "        #         # Calculate total combinations\n",
    "        #         grid = param_grid[model_name]\n",
    "        #         total_combinations = 1\n",
    "        #         for v in grid.values():\n",
    "        #             total_combinations *= len(v)\n",
    "\n",
    "        #         n_iter = min(5, total_combinations)\n",
    "\n",
    "        #         random_search = RandomizedSearchCV(\n",
    "        #             estimator=model,\n",
    "        #             param_distributions=grid,\n",
    "        #             n_iter=n_iter,\n",
    "        #             cv=2,\n",
    "        #             scoring='f1',\n",
    "        #             n_jobs=2,\n",
    "        #             verbose=1,\n",
    "        #             random_state=42\n",
    "        #         )\n",
    "\n",
    "        #         random_search.fit(X_train, y_train)\n",
    "        #         trained_models[model_name] = random_search.best_estimator_\n",
    "\n",
    "        #     except Exception as e:\n",
    "        #         raise CustomException(e, sys)\n",
    "\n",
    "    def training(self, X_train: pd.DataFrame, y_train: pd.Series) -> Dict[str, object]:\n",
    "        \"\"\"Train the models directly without hyperparameter search.\"\"\"\n",
    "        models = self.get_models()\n",
    "        trained_models = {}\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                logging.info(f\"Training {model_name} with default parameters...\")\n",
    "                model.fit(X_train, y_train)\n",
    "                trained_models[model_name] = model\n",
    "            except Exception as e:\n",
    "                raise CustomException(e, sys)\n",
    "\n",
    "        logging.info(\"Model training completed successfully without hyperparameter tuning.\")\n",
    "        return trained_models\n",
    "        # logging.info(\"Model training completed successfully with RandomizedSearchCV\")\n",
    "        # return trained_models\n",
    "\n",
    "\n",
    "    def evaluate_models(self, models: Dict[str, object], X_test: pd.DataFrame, y_test: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Evaluate the models and return a DataFrame of metrics.\"\"\"\n",
    "        metrics_list = []\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, zero_division=1)\n",
    "                f1 = f1_score(y_test, y_pred, zero_division=1)\n",
    "\n",
    "                metrics_list.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Accuracy\": accuracy,\n",
    "                    \"Precision\": precision,\n",
    "                    \"Recall\": recall,\n",
    "                    \"F1 Score\": f1\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                raise CustomException(e, sys)\n",
    "\n",
    "        metrics_df = pd.DataFrame(metrics_list)\n",
    "        logging.info(f\"Evaluation Metrics:\\n{metrics_df}\")\n",
    "        return metrics_df\n",
    "\n",
    "    def select_best_model(self, metrics_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Select the best model based on F1 Score.\"\"\"\n",
    "        try:\n",
    "            best_model_row = metrics_df.loc[metrics_df[\"F1 Score\"].idxmax()]\n",
    "            best_model_name = best_model_row[\"Model\"]\n",
    "            logging.info(f\"Best Model: {best_model_name} with F1 Score: {best_model_row['F1 Score']}\")\n",
    "            return best_model_name\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save_best_model(self, best_model_name: str, trained_models: Dict[str, object]) -> None:\n",
    "            # \"\"\"Save the best model to a .pkl file.\"\"\"\n",
    "        try:\n",
    "            best_model = trained_models[best_model_name]\n",
    "            \n",
    "            # Ensure the model directory exists\n",
    "            os.makedirs(self.config.model_dir, exist_ok=True)\n",
    "            \n",
    "            # Save the best model to the specified path\n",
    "            joblib.dump(best_model, self.config.model_pkl_file)\n",
    "            logging.info(f\"Best model '{best_model_name}' saved to {self.config.model_pkl_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def run_training_pipeline(self) -> pd.DataFrame:\n",
    "            # \"\"\"\n",
    "            # Run the full training pipeline: load data, train models, evaluate them,\n",
    "            # select the best model, and save it as a .pkl file.\n",
    "            # \"\"\"\n",
    "        try:\n",
    "            # 1. Load data\n",
    "            train_df, test_df = self.load_data(self.config.processed_train_path, self.config.processed_test_path)\n",
    "\n",
    "            # 2. Split data\n",
    "            X_train, y_train, X_test, y_test = self.split_data(train_df, test_df)\n",
    "\n",
    "            # 3. Train models\n",
    "            trained_models = self.training(X_train, y_train)\n",
    "\n",
    "            # 4. Evaluate models\n",
    "            metrics_df = self.evaluate_models(trained_models, X_test, y_test)\n",
    "\n",
    "            # 5. Select the best model\n",
    "            best_model_name = self.select_best_model(metrics_df)\n",
    "\n",
    "            # 6. Save the best model\n",
    "            self.save_best_model(best_model_name, trained_models)\n",
    "\n",
    "            logging.info(\"Training pipeline completed successfully.\")\n",
    "            return metrics_df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47021e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_config=ConfigurationManager()\n",
    "    data_train_config=data_config.get_data_training_config()\n",
    "    data_training=ModelTraining(data_train_config)\n",
    "    data_training.run_training_pipeline()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa59326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a604f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43370f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd370d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b847e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ee58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86654a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283636f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a2489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d65bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd265a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e331b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c31c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5f202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626a3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30846ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
